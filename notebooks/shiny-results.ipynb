{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically show plots inside the notebook\n",
    "%matplotlib inline  \n",
    "\n",
    "# reload all modules before executing code\n",
    "%load_ext autoreload\n",
    "%autoreload 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will use this notebook as a basis to walk us through what you did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Feature0</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature677</th>\n",
       "      <th>Feature678</th>\n",
       "      <th>Feature679</th>\n",
       "      <th>Feature680</th>\n",
       "      <th>Feature681</th>\n",
       "      <th>Feature682</th>\n",
       "      <th>Feature683</th>\n",
       "      <th>Feature684</th>\n",
       "      <th>Feature685</th>\n",
       "      <th>Feature686</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>743</td>\n",
       "      <td>3594</td>\n",
       "      <td>81</td>\n",
       "      <td>23154</td>\n",
       "      <td>887</td>\n",
       "      <td>491</td>\n",
       "      <td>368</td>\n",
       "      <td>1322</td>\n",
       "      <td>14624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051950</td>\n",
       "      <td>0.057096</td>\n",
       "      <td>4.309440</td>\n",
       "      <td>0.827737</td>\n",
       "      <td>0.813420</td>\n",
       "      <td>1.118799</td>\n",
       "      <td>0.635217</td>\n",
       "      <td>1.143215</td>\n",
       "      <td>1.450378</td>\n",
       "      <td>0.790279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>249</td>\n",
       "      <td>1523</td>\n",
       "      <td>373</td>\n",
       "      <td>60306</td>\n",
       "      <td>1347</td>\n",
       "      <td>1016</td>\n",
       "      <td>201</td>\n",
       "      <td>1586</td>\n",
       "      <td>45525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.026299</td>\n",
       "      <td>33.007541</td>\n",
       "      <td>1.157097</td>\n",
       "      <td>0.712491</td>\n",
       "      <td>1.149333</td>\n",
       "      <td>0.709755</td>\n",
       "      <td>1.126794</td>\n",
       "      <td>1.171539</td>\n",
       "      <td>0.960270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>815</td>\n",
       "      <td>88</td>\n",
       "      <td>54361</td>\n",
       "      <td>1558</td>\n",
       "      <td>452</td>\n",
       "      <td>105</td>\n",
       "      <td>1758</td>\n",
       "      <td>47862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030360</td>\n",
       "      <td>0.032339</td>\n",
       "      <td>55.780435</td>\n",
       "      <td>0.936845</td>\n",
       "      <td>0.621701</td>\n",
       "      <td>0.688862</td>\n",
       "      <td>0.635621</td>\n",
       "      <td>0.835548</td>\n",
       "      <td>0.894580</td>\n",
       "      <td>0.871643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>376</td>\n",
       "      <td>2095</td>\n",
       "      <td>276</td>\n",
       "      <td>58681</td>\n",
       "      <td>1307</td>\n",
       "      <td>814</td>\n",
       "      <td>241</td>\n",
       "      <td>1527</td>\n",
       "      <td>45351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024164</td>\n",
       "      <td>0.026028</td>\n",
       "      <td>23.155095</td>\n",
       "      <td>1.188455</td>\n",
       "      <td>0.575252</td>\n",
       "      <td>1.237643</td>\n",
       "      <td>0.533353</td>\n",
       "      <td>1.076273</td>\n",
       "      <td>1.224851</td>\n",
       "      <td>1.133792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>78</td>\n",
       "      <td>1946</td>\n",
       "      <td>109</td>\n",
       "      <td>34454</td>\n",
       "      <td>1577</td>\n",
       "      <td>415</td>\n",
       "      <td>513</td>\n",
       "      <td>1785</td>\n",
       "      <td>26612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050253</td>\n",
       "      <td>0.051808</td>\n",
       "      <td>12.761692</td>\n",
       "      <td>1.477104</td>\n",
       "      <td>0.714410</td>\n",
       "      <td>1.062945</td>\n",
       "      <td>0.616509</td>\n",
       "      <td>0.979109</td>\n",
       "      <td>1.204625</td>\n",
       "      <td>0.888280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 688 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID  Feature0  Feature1  Feature2  Feature3  Feature4  Feature5  \\\n",
       "0           1       743      3594        81     23154       887       491   \n",
       "1           2       249      1523       373     60306      1347      1016   \n",
       "2           4       150       815        88     54361      1558       452   \n",
       "3           5       376      2095       276     58681      1307       814   \n",
       "4           7        78      1946       109     34454      1577       415   \n",
       "\n",
       "   Feature6  Feature7  Feature8     ...      Feature677  Feature678  \\\n",
       "0       368      1322     14624     ...        0.051950    0.057096   \n",
       "1       201      1586     45525     ...        0.023671    0.026299   \n",
       "2       105      1758     47862     ...        0.030360    0.032339   \n",
       "3       241      1527     45351     ...        0.024164    0.026028   \n",
       "4       513      1785     26612     ...        0.050253    0.051808   \n",
       "\n",
       "   Feature679  Feature680  Feature681  Feature682  Feature683  Feature684  \\\n",
       "0    4.309440    0.827737    0.813420    1.118799    0.635217    1.143215   \n",
       "1   33.007541    1.157097    0.712491    1.149333    0.709755    1.126794   \n",
       "2   55.780435    0.936845    0.621701    0.688862    0.635621    0.835548   \n",
       "3   23.155095    1.188455    0.575252    1.237643    0.533353    1.076273   \n",
       "4   12.761692    1.477104    0.714410    1.062945    0.616509    0.979109   \n",
       "\n",
       "   Feature685  Feature686  \n",
       "0    1.450378    0.790279  \n",
       "1    1.171539    0.960270  \n",
       "2    0.894580    0.871643  \n",
       "3    1.224851    1.133792  \n",
       "4    1.204625    0.888280  \n",
       "\n",
       "[5 rows x 688 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "features = pd.read_csv('../data/features.csv')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Sickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID  Sickness\n",
       "0           1         0\n",
       "1           2         0\n",
       "2           4         1\n",
       "3           5         0\n",
       "4           7         0"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('../data/labels.csv')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Feature0</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature678</th>\n",
       "      <th>Feature679</th>\n",
       "      <th>Feature680</th>\n",
       "      <th>Feature681</th>\n",
       "      <th>Feature682</th>\n",
       "      <th>Feature683</th>\n",
       "      <th>Feature684</th>\n",
       "      <th>Feature685</th>\n",
       "      <th>Feature686</th>\n",
       "      <th>Sickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>743</td>\n",
       "      <td>3594</td>\n",
       "      <td>81</td>\n",
       "      <td>23154</td>\n",
       "      <td>887</td>\n",
       "      <td>491</td>\n",
       "      <td>368</td>\n",
       "      <td>1322</td>\n",
       "      <td>14624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057096</td>\n",
       "      <td>4.309440</td>\n",
       "      <td>0.827737</td>\n",
       "      <td>0.813420</td>\n",
       "      <td>1.118799</td>\n",
       "      <td>0.635217</td>\n",
       "      <td>1.143215</td>\n",
       "      <td>1.450378</td>\n",
       "      <td>0.790279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>249</td>\n",
       "      <td>1523</td>\n",
       "      <td>373</td>\n",
       "      <td>60306</td>\n",
       "      <td>1347</td>\n",
       "      <td>1016</td>\n",
       "      <td>201</td>\n",
       "      <td>1586</td>\n",
       "      <td>45525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026299</td>\n",
       "      <td>33.007541</td>\n",
       "      <td>1.157097</td>\n",
       "      <td>0.712491</td>\n",
       "      <td>1.149333</td>\n",
       "      <td>0.709755</td>\n",
       "      <td>1.126794</td>\n",
       "      <td>1.171539</td>\n",
       "      <td>0.960270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>815</td>\n",
       "      <td>88</td>\n",
       "      <td>54361</td>\n",
       "      <td>1558</td>\n",
       "      <td>452</td>\n",
       "      <td>105</td>\n",
       "      <td>1758</td>\n",
       "      <td>47862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032339</td>\n",
       "      <td>55.780435</td>\n",
       "      <td>0.936845</td>\n",
       "      <td>0.621701</td>\n",
       "      <td>0.688862</td>\n",
       "      <td>0.635621</td>\n",
       "      <td>0.835548</td>\n",
       "      <td>0.894580</td>\n",
       "      <td>0.871643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>376</td>\n",
       "      <td>2095</td>\n",
       "      <td>276</td>\n",
       "      <td>58681</td>\n",
       "      <td>1307</td>\n",
       "      <td>814</td>\n",
       "      <td>241</td>\n",
       "      <td>1527</td>\n",
       "      <td>45351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026028</td>\n",
       "      <td>23.155095</td>\n",
       "      <td>1.188455</td>\n",
       "      <td>0.575252</td>\n",
       "      <td>1.237643</td>\n",
       "      <td>0.533353</td>\n",
       "      <td>1.076273</td>\n",
       "      <td>1.224851</td>\n",
       "      <td>1.133792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>78</td>\n",
       "      <td>1946</td>\n",
       "      <td>109</td>\n",
       "      <td>34454</td>\n",
       "      <td>1577</td>\n",
       "      <td>415</td>\n",
       "      <td>513</td>\n",
       "      <td>1785</td>\n",
       "      <td>26612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051808</td>\n",
       "      <td>12.761692</td>\n",
       "      <td>1.477104</td>\n",
       "      <td>0.714410</td>\n",
       "      <td>1.062945</td>\n",
       "      <td>0.616509</td>\n",
       "      <td>0.979109</td>\n",
       "      <td>1.204625</td>\n",
       "      <td>0.888280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 689 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID  Feature0  Feature1  Feature2  Feature3  Feature4  Feature5  \\\n",
       "0           1       743      3594        81     23154       887       491   \n",
       "1           2       249      1523       373     60306      1347      1016   \n",
       "2           4       150       815        88     54361      1558       452   \n",
       "3           5       376      2095       276     58681      1307       814   \n",
       "4           7        78      1946       109     34454      1577       415   \n",
       "\n",
       "   Feature6  Feature7  Feature8    ...     Feature678  Feature679  Feature680  \\\n",
       "0       368      1322     14624    ...       0.057096    4.309440    0.827737   \n",
       "1       201      1586     45525    ...       0.026299   33.007541    1.157097   \n",
       "2       105      1758     47862    ...       0.032339   55.780435    0.936845   \n",
       "3       241      1527     45351    ...       0.026028   23.155095    1.188455   \n",
       "4       513      1785     26612    ...       0.051808   12.761692    1.477104   \n",
       "\n",
       "   Feature681  Feature682  Feature683  Feature684  Feature685  Feature686  \\\n",
       "0    0.813420    1.118799    0.635217    1.143215    1.450378    0.790279   \n",
       "1    0.712491    1.149333    0.709755    1.126794    1.171539    0.960270   \n",
       "2    0.621701    0.688862    0.635621    0.835548    0.894580    0.871643   \n",
       "3    0.575252    1.237643    0.533353    1.076273    1.224851    1.133792   \n",
       "4    0.714410    1.062945    0.616509    0.979109    1.204625    0.888280   \n",
       "\n",
       "   Sickness  \n",
       "0         0  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 689 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = features.merge(labels, on = 'Patient ID')\n",
    "target = 'Sickness'\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 689)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint\n",
    "\n",
    "Number of data points : 288\n",
    "Number of features: 685 (not including patient ID and sickness)\n",
    "\n",
    "If I run a classifier on the data with these dimensions, I am most definitely going to overfit my model. \n",
    "\n",
    "An important preprocessing step I always make sure to do is to scale my data. \n",
    "\n",
    "```for every column x in my data:\n",
    "    mean = mean(x)\n",
    "    std = std(x)\n",
    "    for every i in x:\n",
    "        i = (x - mean)/std```\n",
    "\n",
    "This above method will standardize every column to make their range and units equal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "pid = data['Patient ID']\n",
    "labels = data[target]\n",
    "data.drop(['Patient ID', 'Sickness'], axis = 1, inplace = True)\n",
    "col_names = data.columns\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "scaled_data = pd.DataFrame(scaled_data, columns = col_names)\n",
    "scaled_data['Patient ID'] = pid\n",
    "scaled_data['Sickness'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "train, test = train_test_split(scaled_data, test_size = 0.15, random_state = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Class Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a classifier which classifies all datapoints according to the majority class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points with sickness = true: 69\n",
      "number of data points with sickness = false: 219\n",
      "majority class accuracy percentage = 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "clas = []\n",
    "clas.append(len(train[train[target] == 0]))\n",
    "clas.append(len(train[train[target] == 1]))\n",
    "clas = np.array(clas)\n",
    "print('number of data points with sickness = true: ' + str(len(sick)))\n",
    "print('number of data points with sickness = false: ' + str(len(no_sick)))\n",
    "preds = [np.argmax(clas)]*len(test)\n",
    "print('majority class accuracy percentage = ' + str(accuracy_score(preds, test[target])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint\n",
    "Majority class classifier has an accuracy level of 75%. \n",
    "Need to beat this. \n",
    "\n",
    "If I use a any classifier on this dataset, it is going to overfit this data since there are many more features than datapoints. \n",
    "My aim is to reduce the dimensions of the feature space of this dataset. \n",
    "I am going to go about doing this in three ways and compare their outputs: \n",
    "1. Early stopping for decision trees using max_depth\n",
    "2. Logistic regression with Lasso Penalty to remove features which do not affect our outcome\n",
    "3. Using Principal Component Analysis to reduce the number spaces to the ones which affect our output the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(clf, train, test):\n",
    "    clf = clf.fit(train.drop(target, axis = 1), train[target])\n",
    "    preds = clf.predict(test.drop(target, axis = 1))\n",
    "    return accuracy_score(preds, test[target]), clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with build in GridSerch for selecting the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is :0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "parameters = {'max_depth': list(range(1, 25))}\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "best_clf = grid_search.GridSearchCV(tree_clf, parameters)\n",
    "acc, clf = get_acc(best_clf, train, test)\n",
    "print('test accuracy is :' + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with self implemented search for best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is :0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# params: get all max_depths of trees that I want to try\n",
    "max_depths = list(range(1, 25))\n",
    "\n",
    "iters = 50\n",
    "\n",
    "best_acc = 0\n",
    "best_depth = max(max_depths)\n",
    "for max_depth in max_depths:\n",
    "    mean_acc = 0\n",
    "    for i in range(iters):\n",
    "        train_small, validation = train_test_split(train, test_size = 0.1)\n",
    "        curr_acc, _ = get_acc(DecisionTreeClassifier(max_depth = max_depth), train_small, validation)\n",
    "        mean_acc += curr_acc\n",
    "    curr_acc = mean_acc/(1.0*iters)\n",
    "    if curr_acc > best_acc:\n",
    "        best_acc = curr_acc\n",
    "        best_depth = max_depth\n",
    "\n",
    "\n",
    "# now lets test our best Decision Tree Classifier\n",
    "acc, best_clf = get_acc(DecisionTreeClassifier(max_depth = best_depth), train, test)\n",
    "print('test accuracy is :' + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Problems with Decision Tree\n",
    "\n",
    "1. The problem with decision trees is that it chooses the best feature to split on by checking its accuracy after split on the single feature. Hence, feature combination is not possible. \n",
    "2. Decision Trees are not stable as a small alterations in training data will form structurally different dicision trees. \n",
    "3. Results can often be improved by using Boosting algorithms or Random Forests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Lasso Penalty\n",
    "\n",
    "The parameter of logistic regression which I shall be tuning here is the 'C' parameter. This is the inverse of the regularization strenght. \n",
    "I shall be using l1 penalty or Lasso penalization for feature selection. \n",
    "The more I reduce C, the quicker the logistic regression should starting zeroing out features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Logistic Regression using built in GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is :0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "parameters = {'C': [10**(-i) for i in range(5)]}\n",
    "log_clf = LogisticRegression(penalty = 'l1')\n",
    "best_clf = grid_search.GridSearchCV(log_clf, parameters)\n",
    "acc, clf = get_acc(best_clf, train, test)\n",
    "print('test accuracy is :' + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Logistic Regression using self implemented search for best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is :0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "iters = 50\n",
    "lambdas = []\n",
    "for i in range(6):\n",
    "    lambdas.append(10**(-i))\n",
    "\n",
    "best_acc = 0\n",
    "best_l = None\n",
    "for l in lambdas:\n",
    "    mean_acc = 0\n",
    "    for i in range(iters):\n",
    "        train_small, validation = train_test_split(train, test_size = 0.1)\n",
    "        curr_acc, clf = get_acc(LogisticRegression(C=l, penalty='l1'), train_small, validation)\n",
    "        mean_acc += curr_acc\n",
    "    curr_acc = mean_acc/(1.0*iters)\n",
    "    if curr_acc > best_acc:\n",
    "        best_acc = curr_acc\n",
    "        best_l = l\n",
    "\n",
    "acc, best_clf = get_acc(LogisticRegression(C=best_l, penalty='l1'), train, test)\n",
    "print('test accuracy is :' + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Let's try and better our performance of decision trees by using Random Forests. \n",
    "The advantages of using Random Forests are listed below: \n",
    "1. Even if you increase the number of trees used in the algorithm (by increasing n_estimators), it is hard to overfit Random Forests\n",
    "2. It can handle thousands of input variables without having to delete any features\n",
    "3. It gives estimates of what variables are important in the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests parameter selection using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is :0.8409090909090909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "parameters = {'n_estimators': [100, 250, 500, 750, 1000]}\n",
    "rf_clf = RandomForestClassifier()\n",
    "best_clf = grid_search.GridSearchCV(rf_clf, parameters)\n",
    "acc, clf = get_acc(best_clf, train, test)\n",
    "print('test accuracy is :' + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest self implemented parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def best_RF_Accuracy(train, test, n_est = [100, 250, 500, 750, 1000], iters = 25):\n",
    "    best_acc = 0\n",
    "    best_n = None\n",
    "    for n in n_est:\n",
    "        mean_acc = 0\n",
    "        for i in range(iters):\n",
    "            train_small, validation = train_test_split(train, test_size = 0.1)\n",
    "            curr_acc, clf = get_acc(RandomForestClassifier(n_estimators = n), train_small, validation)\n",
    "            mean_acc += curr_acc\n",
    "        curr_acc = mean_acc/(1.0*iters)\n",
    "        if curr_acc > best_acc:\n",
    "            best_acc = curr_acc\n",
    "            best_n = n\n",
    "\n",
    "    acc, best_clf = get_acc(RandomForestClassifier(n_estimators = best_n), train, test)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is :0.9318181818181818\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy is :' + str(best_RF_Accuracy(train, test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    }
   ],
   "source": [
    "print(best_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis\n",
    "\n",
    "Principal Component Analysis not only helps us find relations between our features but also reduces \n",
    "the dimensionality of our data to the desired output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def create_pca_data(n_dim):\n",
    "    pca = PCA(n_components=n_dim)\n",
    "    pca.fit(scaled_data)\n",
    "    pca_train, pca_test = train_test_split(scaled_data, test_size = 0.15, random_state = 30)\n",
    "    return pca_train, pca_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of PCA\n",
    "\n",
    "Here we see that lower dimensions produce better results for Random Forests running on our reduced dimension data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n",
      "0.9090909090909091\n",
      "0.8636363636363636\n",
      "0.8636363636363636\n",
      "0.8863636363636364\n",
      "0.8863636363636364\n",
      "0.8409090909090909\n",
      "0.8409090909090909\n",
      "0.8636363636363636\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    pca_train, pca_test = create_pca_data(i)\n",
    "    print(best_RF_Accuracy(train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result: The best model was a Random Forest without dimensionality reduction, with n_estimators around 750 \n",
    "\n",
    "Accuracy level was 93.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
